{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvO0RLYKqs3C"
      },
      "source": [
        "# **Linear regression using PyTorch built-ins**\n",
        "\n",
        "Linear Regression is the simplest form of Neural Network. So, let's understand Neural Network with Linear regression first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1zt1WxVrg4P"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpxsFLWQrK9g"
      },
      "source": [
        "# Let's begin by importing the torch.nn package from PyTorch, which contains utility classes for building neural networks.\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0kGAPTErWjj"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70], \n",
        "                   [74, 66, 43], \n",
        "                   [91, 87, 65], \n",
        "                   [88, 134, 59], \n",
        "                   [101, 44, 37], \n",
        "                   [68, 96, 71], \n",
        "                   [73, 66, 44], \n",
        "                   [92, 87, 64], \n",
        "                   [87, 135, 57], \n",
        "                   [103, 43, 36], \n",
        "                   [68, 97, 70]], \n",
        "                  dtype='float32')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7COA8TcreZ6"
      },
      "source": [
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119],\n",
        "                    [57, 69], \n",
        "                    [80, 102], \n",
        "                    [118, 132], \n",
        "                    [21, 38], \n",
        "                    [104, 118], \n",
        "                    [57, 69], \n",
        "                    [82, 100], \n",
        "                    [118, 134], \n",
        "                    [20, 38], \n",
        "                    [102, 120]], \n",
        "                   dtype='float32')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0JuvdsCrpdm"
      },
      "source": [
        "# convert inputs and targets from numpys to pytorch tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gNazjiLr1Hf"
      },
      "source": [
        "In a real world, the dataset is usually huge. It has millions or records. In such cases training the model with the entire dataset at once is troublesome. It takes time and resources. \n",
        "\n",
        "So, let' learn how we can train a model in batches. \n",
        "\n",
        "**TensorDataset** - It allows access to rows from inputs and targets as tuples. It also provides standard APIs for working with many different types of datasets in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvt9w1IdsjlA"
      },
      "source": [
        "# Import TensorDataset\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo7sTfWis5Vp",
        "outputId": "76503f10-95a7-47c8-84f8-b10cb9a2bd80"
      },
      "source": [
        "# Now we'll pass our datset to TensorDataset\n",
        "train_data = TensorDataset(inputs, targets)\n",
        "train_data [0:3] #now we can access rows as tuple. This gives us first three rows of inputs and first 3 rows of targets."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]), tensor([[ 56.,  70.],\n",
              "         [ 81., 101.],\n",
              "         [119., 133.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93iPl036tYa5"
      },
      "source": [
        "**DataLoader** - It can split the data into batches of a predefined size while training. It also provides other utilities like shuffling and random sampling of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PbyOAqlt9EA"
      },
      "source": [
        "# Import DataLoader\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srxoIYhEuLMl"
      },
      "source": [
        "# Define data loader\n",
        "batch_size = 5\n",
        "dl = DataLoader(train_data, batch_size, shuffle=True) #when Shuffle=true DataLoader shuffles the data before creating batches"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Ims6bBvwMh"
      },
      "source": [
        "# nn.Linear\n",
        "\n",
        "Instead of initializing the weights & biases manually, we can define the model using the nn.Linear class from PyTorch, which does it automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqB_o73RvyVv",
        "outputId": "58cfa937-36c0-4bc2-9e6d-f1385fcdf93b"
      },
      "source": [
        "# Define model\n",
        "model = nn.Linear(3, 2) #3 is the the number of input variables, and 2 are the target variables. This does everything automatically."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.5189,  0.5301, -0.3422],\n",
            "        [ 0.3069,  0.2692, -0.3315]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.4331, 0.5253], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKnBQw0twBLv",
        "outputId": "e0bd5916-dbd4-49ba-b616-8a5ecdcbf673"
      },
      "source": [
        "# For our linear regression model, we have one weight matrix and one bias matrix. To get all the weights and bias matrices present in the model.\n",
        "list(model.parameters())\n",
        "\n",
        "# Individually\n",
        "#print(model.weight)\n",
        "#print(model.bias)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.5189,  0.5301, -0.3422],\n",
              "         [ 0.3069,  0.2692, -0.3315]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.4331, 0.5253], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11Doq1EVx5KH"
      },
      "source": [
        "w = model.weight\n",
        "b = model.bias"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ7x25diwbi3",
        "outputId": "dbc4f7cb-76c6-45cc-94ea-eaccbbd33e20"
      },
      "source": [
        "# Next, let's generate predictions\n",
        "pred = inputs @ w.t() + b\n",
        "pred"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[59.1215, 26.7143],\n",
              "        [72.4096, 30.9310],\n",
              "        [96.7735, 44.0774],\n",
              "        [63.5006, 31.1427],\n",
              "        [63.1808, 24.3433],\n",
              "        [59.1103, 26.7520],\n",
              "        [71.5372, 30.3302],\n",
              "        [96.9502, 44.0528],\n",
              "        [63.5118, 31.1050],\n",
              "        [62.3197, 23.7048],\n",
              "        [58.2492, 26.1136],\n",
              "        [72.3984, 30.9687],\n",
              "        [97.6458, 44.6782],\n",
              "        [64.3617, 31.7812],\n",
              "        [63.1920, 24.3056]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HRSP3MKxGIZ",
        "outputId": "bfc77270-9f5a-4af0-de20-eef2f8f95dfe"
      },
      "source": [
        "targets"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 57.,  69.],\n",
              "        [ 80., 102.],\n",
              "        [118., 132.],\n",
              "        [ 21.,  38.],\n",
              "        [104., 118.],\n",
              "        [ 57.,  69.],\n",
              "        [ 82., 100.],\n",
              "        [118., 134.],\n",
              "        [ 20.,  38.],\n",
              "        [102., 120.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCNIVEagzWqG"
      },
      "source": [
        "# **Loss Function**\n",
        "Instead of defining a loss function manually, we can use the built-in loss functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUTxLNlXzxif"
      },
      "source": [
        "# Import nn.functional. This package contains many useful loss functions.\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klz3Oi3-z5ty"
      },
      "source": [
        "# Define loss function\n",
        "lf = F.mse_loss"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gojFqdBXz6V0",
        "outputId": "d88e2636-2afe-496b-9449-9420086f95fa"
      },
      "source": [
        "# Compute the loss for the current predictions of our model.\n",
        "mse = lf(pred, targets)\n",
        "print(mse)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2766.3408, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWi3-srK0J4u"
      },
      "source": [
        "# **Optimizer**\n",
        "Instead of performing Gradient Descent manually, we can use the optimizer optim.SGD. SGD is short for \"stochastic gradient descent\". The term stochastic indicates that samples are selected in random batches instead of as a single group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFZd59D30nI4"
      },
      "source": [
        "# Define optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbrKp15r0jAn"
      },
      "source": [
        "The optim.SGD does the same as\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "Note that model.parameters() is passed as an argument to optim.SGD so that the optimizer knows which matrices should be modified during the update step. Also, we can specify a learning rate that controls the amount by which the parameters are modified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFzus1DC0_kC"
      },
      "source": [
        "# **Train the model**\n",
        "Let's train the model\n",
        "\n",
        "1. Generate predictions\n",
        "2. Calculate the loss\n",
        "3. Compute gradients w.r.t the weights and biases\n",
        "4. Adjust the weights by subtracting a small quantity proportional to the  \n",
        "   gradient\n",
        "5. Reset the gradients to zero\n",
        "\n",
        "The only change is that we'll work batches of data instead of processing the \n",
        "entire training data in every iteration. Let's define a utility function fit \n",
        "that trains the model for a given number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtOlvIqs2Eec"
      },
      "source": [
        "# we will be using the function everytime from now instead of writing it everytime\n",
        "\n",
        "# Utility function to train the model\n",
        "def fit(num_epochs, model, lf, opt, dl):\n",
        "    \n",
        "    # Repeat for given number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # Train with batches of data\n",
        "        for xb,yb in dl:\n",
        "            \n",
        "            # 1. Generate predictions\n",
        "            pred = model(xb)\n",
        "            \n",
        "            # 2. Calculate loss\n",
        "            loss = lf(pred, yb)\n",
        "            \n",
        "            # 3. Compute gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # 4. Update parameters using gradients. opt.step is doing this w -= w.grad * 1e-5, b -= b.grad * 1e-5\n",
        "            opt.step()\n",
        "            \n",
        "            # 5. Reset the gradients to zero. This is doing w.grad.zero_(), b.grad.zero_()\n",
        "            opt.zero_grad()\n",
        "        \n",
        "        # Print the loss at the end of every 10th epoch\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XAXwn4E2mJv"
      },
      "source": [
        "Some things to note above:\n",
        "\n",
        "We use the data loader defined earlier to get batches of data for every iteration.\n",
        "\n",
        "Instead of updating parameters (weights and biases) manually, we use opt.step to perform the update and opt.zero_grad to reset the gradients to zero.\n",
        "\n",
        "We've also added a log statement that prints the loss from the last batch of data for every 10th epoch to track training progress. loss.item returns the actual value stored in the loss tensor.\n",
        "\n",
        "Let's train the model for 100 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXU-hd9C2sQH",
        "outputId": "60dca07f-9ad3-47a1-cab7-89e08b320060"
      },
      "source": [
        "# we can see the loss after every 10th epoch\n",
        "fit(100, model, lf, opt, dl)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [10/100], Loss: 848.6642\n",
            "Epoch [20/100], Loss: 366.5586\n",
            "Epoch [30/100], Loss: 447.7979\n",
            "Epoch [40/100], Loss: 204.1231\n",
            "Epoch [50/100], Loss: 172.7939\n",
            "Epoch [60/100], Loss: 132.5098\n",
            "Epoch [70/100], Loss: 123.9473\n",
            "Epoch [80/100], Loss: 55.9234\n",
            "Epoch [90/100], Loss: 34.9637\n",
            "Epoch [100/100], Loss: 91.8006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5vxmxgv2xYK",
        "outputId": "0383a47e-481d-494f-f6e8-74b98b49d5f5"
      },
      "source": [
        "# Generate predictions\n",
        "pred = inputs @ w.t() + b\n",
        "pred"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 58.6706,  72.0140],\n",
              "        [ 77.5597,  95.8702],\n",
              "        [125.3118, 140.4297],\n",
              "        [ 30.0586,  46.3743],\n",
              "        [ 88.7928, 105.4807],\n",
              "        [ 57.5060,  70.9952],\n",
              "        [ 76.5285,  95.0547],\n",
              "        [125.1662, 140.5728],\n",
              "        [ 31.2232,  47.3930],\n",
              "        [ 88.9262, 105.6840],\n",
              "        [ 57.6393,  71.1985],\n",
              "        [ 76.3951,  94.8515],\n",
              "        [126.3431, 141.2452],\n",
              "        [ 29.9252,  46.1710],\n",
              "        [ 89.9575, 106.4995]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJQc_HGB3S0S",
        "outputId": "412cfbba-e0ff-42bb-9919-5acb4c22fde6"
      },
      "source": [
        "targets"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 57.,  69.],\n",
              "        [ 80., 102.],\n",
              "        [118., 132.],\n",
              "        [ 21.,  38.],\n",
              "        [104., 118.],\n",
              "        [ 57.,  69.],\n",
              "        [ 82., 100.],\n",
              "        [118., 134.],\n",
              "        [ 20.,  38.],\n",
              "        [102., 120.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnlcGM7n3Ufu"
      },
      "source": [
        "The predictions are quite close to our targets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t8b3gLF3fdz",
        "outputId": "283f4104-ff9a-4fe2-fb61-e506c6068420"
      },
      "source": [
        "# You can also make predictions of crop yields for new regions by passing a batch containing a single row of input.\n",
        "model(torch.tensor([[75, 63, 44.]]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[54.2849, 68.1723]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABXkqVdm3onI"
      },
      "source": [
        "## **Now to predict using a Neural Network this is what we can do**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8I77N0R8EHp"
      },
      "source": [
        "model2 = nn.Sequential(\n",
        "    nn.Linear(3,5), #this is taking 3 inputs, and giving out 5 outputs (this is the input layer)\n",
        "    nn.Sigmoid(),   #this is the hidden layer (the activation function. We can also use nn.ReLu)\n",
        "    nn.Linear(5,2)  #this is taking those 5 outputs as inputs and giving two target outputs)\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yySWqY7H9LD9"
      },
      "source": [
        "# Define optimizer\n",
        "opt2 = torch.optim.SGD(model2.parameters(), lr=1e-3) #experiement with the learning rate if the mse is high"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v56fnUS09Skm",
        "outputId": "16661edd-eb19-4c1b-9fb6-cb691b0ac371"
      },
      "source": [
        "# we can see the loss after every 10th epoch\n",
        "fit(100, model2, lf, opt2, dl)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [10/100], Loss: 5289.6348\n",
            "Epoch [20/100], Loss: 2164.5210\n",
            "Epoch [30/100], Loss: 3438.3008\n",
            "Epoch [40/100], Loss: 1262.5712\n",
            "Epoch [50/100], Loss: 808.3759\n",
            "Epoch [60/100], Loss: 2130.7808\n",
            "Epoch [70/100], Loss: 2453.2122\n",
            "Epoch [80/100], Loss: 1623.0161\n",
            "Epoch [90/100], Loss: 1074.6339\n",
            "Epoch [100/100], Loss: 1256.4371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GexemVje9cdS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}